# NPS Website Scrape
 
All code can be found under the jupyter notebook file. Websites are based on a 4-letter alpha for each of the 394 National Park units, found in the csv file. This program uses chromedriver and is set to only run for the first 50 parks as is. It will calculate 10 transportation-related fields for each national park in the U.S. These calculations use basic natural language processing where key words or phrases are aggregated on all pages for each website, and cutoffs are used based on total number of web pages per park where key word/phrases are used. 
